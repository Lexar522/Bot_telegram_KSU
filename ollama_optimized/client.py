"""
–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –∫–ª—ñ—î–Ω—Ç OLLAMA –∑ —É—Å—ñ–º–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏
"""
import aiohttp
import asyncio
import time
import json
import re
from typing import Optional, Dict, List, AsyncGenerator
from config import OLLAMA_API_URL, OLLAMA_MODEL
from ollama_optimized.prompt_builder import PromptBuilder
from ollama_optimized.context_optimizer import ContextOptimizer
from ollama_optimized.question_classifier import QuestionClassifier
from ollama_optimized.cache import ResponseCache
from ollama_optimized.semantic_cache import SemanticCache
from ollama_optimized.validators.multi_level import MultiLevelValidator
from ollama_optimized.metrics.collector import MetricsCollector
from services.knowledge_service import KnowledgeService
import logging

logger = logging.getLogger(__name__)


class OptimizedOllamaClient:
    """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –∫–ª—ñ—î–Ω—Ç OLLAMA –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º, –≤–∞–ª—ñ–¥–∞—Ü—ñ—î—é —Ç–∞ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    
    def __init__(self):
        self.api_url = OLLAMA_API_URL
        self.model = OLLAMA_MODEL
        self.prompt_builder = PromptBuilder()
        self.context_optimizer = ContextOptimizer()
        self.question_classifier = QuestionClassifier()
        self.cache = ResponseCache(max_size=200)
        self.semantic_cache = SemanticCache(max_size=200, similarity_threshold=0.7)
        self.validator = MultiLevelValidator()
        self.metrics = MetricsCollector()
        self.knowledge_service = KnowledgeService()
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è)
        self.generation_params = {
            "factual": {
                "temperature": 0.05,  # –ù–∏–∑—å–∫–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ
                "top_p": 0.4,  # –ó–≤—É–∂–µ–Ω–∏–π –¥–ª—è —Ñ–æ–∫—É—Å—É
                "num_predict": 300,  # –ë—ñ–ª—å—à–µ –¥–ª—è –ø–æ–≤–Ω–æ—Ç–∏
                "repeat_penalty": 1.5,  # –í–∏—â–∞ –¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è –ø–æ–≤—Ç–æ—Ä—ñ–≤
                "top_k": 25  # –ú–µ–Ω—à–µ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ
            },
            "comparison": {
                "temperature": 0.15,  # –¢—Ä–æ—Ö–∏ –≤–∏—â–∞ –¥–ª—è —Ç–≤–æ—Ä—á–æ—Å—Ç—ñ
                "top_p": 0.6,
                "num_predict": 600,
                "repeat_penalty": 1.6,
                "top_k": 35
            },
            "admission": {
                "temperature": 0.0,  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ
                "top_p": 0.25,  # –î—É–∂–µ –∑–≤—É–∂–µ–Ω–∏–π
                "num_predict": 500,  # –ë—ñ–ª—å—à–µ –¥–ª—è –ø–æ–≤–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
                "repeat_penalty": 1.5,
                "top_k": 15  # –ú—ñ–Ω—ñ–º—É–º –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤
            },
            "tuition": {
                "temperature": 0.0,  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ —Ü–∏—Ñ—Ä
                "top_p": 0.25,
                "num_predict": 400,
                "repeat_penalty": 1.5,
                "top_k": 15
            },
            "faculties": {
                "temperature": 0.05,
                "top_p": 0.4,
                "num_predict": 350,
                "repeat_penalty": 1.4,
                "top_k": 25
            },
            "procedural": {
                "temperature": 0.1,  # –¢—Ä–æ—Ö–∏ –≤–∏—â–∞ –¥–ª—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ
                "top_p": 0.5,
                "num_predict": 450,
                "repeat_penalty": 1.5,
                "top_k": 30
            },
            "default": {
                "temperature": 0.05,
                "top_p": 0.4,
                "num_predict": 400,
                "repeat_penalty": 1.5,
                "top_k": 25
            }
        }
    
    async def generate_response(
        self, 
        prompt: str, 
        context: List[Dict] = None,
        use_cache: bool = True
    ) -> str:
        """
        –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º —Ç–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        """
        start_time = time.time()
        
        if not prompt:
            return "–í–∏–±–∞—á, –Ω–µ –∑—Ä–æ–∑—É–º—ñ–≤ –ø–∏—Ç–∞–Ω–Ω—è. –°–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏."
        
        # 1. –ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î–º–æ –ø–∏—Ç–∞–Ω–Ω—è
        question_type = self.question_classifier.classify(prompt)
        
        # 2. –û—Ç—Ä–∏–º—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        full_context = self.knowledge_service.get_context_for_prompt(prompt)
        optimized_context = self.context_optimizer.optimize_context(
            prompt, 
            full_context["structured_json"]
        )
        
        # 3. –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à (—Å–ø–æ—á–∞—Ç–∫—É —Ç–æ—á–Ω–∏–π, –ø–æ—Ç—ñ–º —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π)
        if use_cache:
            # –¢–æ—á–Ω–∏–π –ø–æ—à—É–∫
            cached_response = self.cache.get(prompt, optimized_context)
            if cached_response:
                response_time = time.time() - start_time
                self.metrics.record_request(
                    prompt, cached_response, response_time, 
                    from_cache=True, question_type=question_type, validation_passed=True
                )
                logger.info(f"Exact cache hit for question type: {question_type}")
                return cached_response
            
            # –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫
            semantic_result = self.semantic_cache.get(prompt, optimized_context)
            if semantic_result:
                cached_response, similarity = semantic_result
                response_time = time.time() - start_time
                self.metrics.record_request(
                    prompt, cached_response, response_time, 
                    from_cache=True, question_type=question_type, validation_passed=True
                )
                logger.info(f"Semantic cache hit (similarity: {similarity:.2f}) for question type: {question_type}")
                return cached_response
        
        # 4. –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø–∏—Ç–∞–Ω–Ω—è –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è
        analyzed_query = self._analyze_and_enhance_query(prompt, question_type)
        
        # 5. –§–æ—Ä–º—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –ø—Ä–æ–º–ø—Ç –∑ –∞–Ω–∞–ª—ñ–∑–æ–º –ø–∏—Ç–∞–Ω–Ω—è
        system_prompt = self.prompt_builder.build_system_prompt(
            question_type, 
            optimized_context,
            user_query=prompt
        )
        
        # 6. –î–æ–¥–∞—î–º–æ Chain-of-Thought –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å
        if self._should_use_cot(question_type, prompt):
            full_prompt = self._build_cot_prompt(system_prompt, analyzed_query)
        else:
            # –ü–æ–∫—Ä–∞—â–µ–Ω–µ —Ñ–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è –ø–∏—Ç–∞–Ω–Ω—è –¥–ª—è –º–æ–¥–µ–ª—ñ
            full_prompt = f"""{system_prompt}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ü–ò–¢–ê–ù–ù–Ø –ö–û–†–ò–°–¢–£–í–ê–ß–ê:
{prompt}

–ü–†–û–ê–ù–ê–õ–Ü–ó–û–í–ê–ù–ï –ü–ò–¢–ê–ù–ù–Ø:
{analyzed_query}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
1. –£–≤–∞–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π –ø–∏—Ç–∞–Ω–Ω—è
2. –ó–Ω–∞–π–¥–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å –≤–∏—â–µ
3. –°—Ñ–æ—Ä–º—É–π —Ç–æ—á–Ω—É, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å
4. –ü–µ—Ä–µ–≤—ñ—Ä –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞ —Å–ø–∏—Å–∫–æ–º —Å–∞–º–æ–ø–µ—Ä–µ–≤—ñ—Ä–∫–∏

–í–Ü–î–ü–û–í–Ü–î–¨ (—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞, –∑ –¥–∞–Ω–∏–º–∏ –∑ –±–∞–∑–∏ –∑–Ω–∞–Ω—å):"""
        
        # 7. –û—Ç—Ä–∏–º—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó (–ø–æ–∫—Ä–∞—â–µ–Ω—ñ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è)
        params = self.generation_params.get(
            question_type, 
            self.generation_params["default"]
        )
        
        # –ê–¥–∞–ø—Ç—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –¥–æ–≤–∂–∏–Ω–∏ –ø–∏—Ç–∞–Ω–Ω—è —Ç–∞ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
        params = self._adapt_params(params, len(prompt))
        
        # –ü–æ–∫—Ä–∞—â–µ–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è (–≤–∂–µ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –≤–∏—â–µ)
        # –ù–µ –∑–º—ñ–Ω—é—î–º–æ, —â–æ–± –Ω–µ –∑—ñ–ø—Å—É–≤–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—é
        
        # 7. –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å (–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è chat API)
        response = await self._generate_with_retry(
            full_prompt, 
            params, 
            max_retries=3,
            context=context if context else []
        )
        
        # 7.1. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —è–∫–æ—Å—Ç—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (–º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π fallback —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –∫—Ä–∏—Ç–∏—á–Ω–æ)
        response_lower = response.lower() if response else ""
        
        # Fallback —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —è–≤–Ω–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞
        if not response or len(response.strip()) < 30 or "–Ω–µ –≤–¥–∞–ª–æ—Å—è" in response_lower:
            # –¢—ñ–ª—å–∫–∏ –¥–ª—è –ø–∏—Ç–∞–Ω—å –ø—Ä–æ –≤—Å—Ç—É–ø –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback
            if question_type == "admission":
                logger.warning(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –¥–ª—è –≤—Å—Ç—É–ø—É, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback: {prompt[:50]}")
                response = self._get_admission_fallback(prompt)
            else:
                # –î–ª—è —ñ–Ω—à–∏—Ö –ø–∏—Ç–∞–Ω—å - —Å–ø—Ä–æ–±—É—î–º–æ —Ä–µ–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑ –∫—Ä–∞—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                logger.warning(f"–ü–æ–≥–∞–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å, —Ä–µ–≥–µ–Ω–µ—Ä—É—î–º–æ: {prompt[:50]}")
                strict_params = params.copy()
                strict_params["temperature"] = 0.0
                strict_params["top_p"] = 0.2
                strict_params["num_predict"] = min(600, params.get("num_predict", 350) * 2)
                response = await self._generate_with_retry(
                full_prompt, 
                strict_params, 
                max_retries=2,
                context=context if context else []
            )
        
        # 8. –í–∞–ª—ñ–¥—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å (—Ç—ñ–ª—å–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏)
        validation_result = self.validator.validate(response, prompt)
        
        # –†–µ–≥–µ–Ω–µ—Ä—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –ø–æ–º–∏–ª–∫–∞—Ö (–∑–∞–±–æ—Ä–æ–Ω–µ–Ω—ñ —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç–∏, –ø–æ—Ä–æ–∂–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å)
        critical_errors = [
            "–∑–∞–±–æ—Ä–æ–Ω–µ–Ω–∏–π —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç" in validation_result.error_message.lower() if validation_result.error_message else False,
            not response or len(response.strip()) < 20
        ]
        
        if not validation_result.is_valid and any(critical_errors):
            logger.warning(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó: {validation_result.error_message}")
            # –†–µ–≥–µ–Ω–µ—Ä—É—î–º–æ –∑ –±—ñ–ª—å—à —Å—É–≤–æ—Ä–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            strict_params = params.copy()
            strict_params["temperature"] = 0.0
            strict_params["top_p"] = 0.15
            strict_params["repeat_penalty"] = 1.7
            strict_params["num_predict"] = min(600, params.get("num_predict", 400) * 1.5)
            
            # –î–æ–¥–∞—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –≤ –ø—Ä–æ–º–ø—Ç
            enhanced_prompt = f"""{full_prompt}

‚ö†Ô∏è –í–ê–ñ–õ–ò–í–û: –ü–æ–ø–µ—Ä–µ–¥–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å –º—ñ—Å—Ç–∏–ª–∞ –ø–æ–º–∏–ª–∫–∏: {validation_result.error_message}
–°—Ñ–æ—Ä–º—É–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ó–ù–û–í–£, —É–Ω–∏–∫–Ω—É–≤—à–∏ —Ü–∏—Ö –ø–æ–º–∏–ª–æ–∫. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò –¥–∞–Ω—ñ –∑ –±–∞–∑–∏ –∑–Ω–∞–Ω—å –≤–∏—â–µ."""
            
            response = await self._generate_with_retry(
                enhanced_prompt, 
                strict_params, 
                max_retries=2,
                context=context if context else []
            )
            
            # –ü–æ–≤—Ç–æ—Ä–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è
            validation_result = self.validator.validate(response, prompt)
            self.metrics.metrics["regeneration_count"] += 1
        elif not validation_result.is_valid:
            # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏ - –ø—Ä–æ—Å—Ç–æ –ª–æ–≥—É—î–º–æ
            logger.info(f"–ù–µ –∫—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó: {validation_result.error_message}")
        
        # 9. –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –∫–µ—à (–æ–±–∏–¥–≤–∞ —Ç–∏–ø–∏)
        if validation_result.is_valid and use_cache:
            self.cache.set(prompt, optimized_context, response)
            self.semantic_cache.set(prompt, optimized_context, response)
        
        # 10. –ó–∞–ø–∏—Å—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
        response_time = time.time() - start_time
        self.metrics.record_request(
            prompt, response, response_time, 
            from_cache=False, question_type=question_type, 
            validation_passed=validation_result.is_valid
        )
        
        return response
    
    def _analyze_and_enhance_query(self, query: str, question_type: str) -> str:
        """–ê–Ω–∞–ª—ñ–∑ —Ç–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –ø–∏—Ç–∞–Ω–Ω—è –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è –º–æ–¥–µ–ª–ª—é"""
        query_lower = query.lower()
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ —Ç–∞ —ñ–Ω—Ç–µ–Ω—Ç
        keywords = []
        intent = question_type
        
        # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –ø–∏—Ç–∞–Ω—å
        if question_type == "admission":
            keywords.extend(["–≤—Å—Ç—É–ø", "–Ω–º—Ç", "–∫–∞–º–ø–∞–Ω—ñ—è", "–ø—Ä–∞–≤–∏–ª–∞", "—Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó"])
        elif question_type == "tuition":
            keywords.extend(["–≤–∞—Ä—Ç—ñ—Å—Ç—å", "—Ü—ñ–Ω–∞", "–∫–æ—à—Ç—É—î", "–æ–ø–ª–∞—Ç–∞", "—Ç–∞—Ä–∏—Ñ–∏"])
        elif question_type == "faculties":
            keywords.extend(["—Ñ–∞–∫—É–ª—å—Ç–µ—Ç", "—Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ—Å—Ç—å", "–Ω–∞–ø—Ä—è–º", "–æ—Å–≤—ñ—Ç–Ω—ñ –ø—Ä–æ–≥—Ä–∞–º–∏"])
        elif question_type == "procedural":
            keywords.extend(["—è–∫", "–∫—Ä–æ–∫–∏", "–ø–æ–¥–∞—Ç–∏", "–æ—Ñ–æ—Ä–º–∏—Ç–∏", "–ø—Ä–æ—Ü–µ–¥—É—Ä–∞"])
        elif question_type == "comparison":
            keywords.extend(["—Ä—ñ–∑–Ω–∏—Ü—è", "–ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è", "–∫—Ä–∞—â–µ", "–≤—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è"])
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –≤ –ø–∏—Ç–∞–Ω–Ω—ñ
        found_keywords = [kw for kw in keywords if kw in query_lower]
        
        # –§–æ—Ä–º—É—î–º–æ –ø–æ–∫—Ä–∞—â–µ–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è
        enhanced = f"""–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è: "{query}"

–ê–Ω–∞–ª—ñ–∑:
- –¢–∏–ø –ø–∏—Ç–∞–Ω–Ω—è: {question_type}
- –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞: {', '.join(found_keywords) if found_keywords else '–∑–∞–≥–∞–ª—å–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è'}
- –©–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–Ω–∞–π—Ç–∏: {self._get_expected_info(question_type)}

–ó–∞–≤–¥–∞–Ω–Ω—è: –ó–Ω–∞–π–¥–∏ –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ {self._get_search_target(question_type)} —Ç–∞ –¥–∞–π —Ç–æ—á–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å."""
        
        return enhanced
    
    def _get_expected_info(self, question_type: str) -> str:
        """–û—á—ñ–∫—É–≤–∞–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –¥–ª—è —Ç–∏–ø—É –ø–∏—Ç–∞–Ω–Ω—è"""
        mapping = {
            "admission": "–ø—Ä–∞–≤–∏–ª–∞ –≤—Å—Ç—É–ø—É, –ù–ú–¢, —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó, –≤—Å—Ç—É–ø–Ω–∞ –∫–∞–º–ø–∞–Ω—ñ—è, –µ–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∏–π –∫–∞–±—ñ–Ω–µ—Ç",
            "tuition": "–≤–∞—Ä—Ç—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è, —Ç–∞—Ä–∏—Ñ–∏, –æ–ø–ª–∞—Ç–∞ –∑–∞ —Å–µ–º–µ—Å—Ç—Ä/—Ä—ñ–∫",
            "faculties": "—Ñ–∞–∫—É–ª—å—Ç–µ—Ç–∏, —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—Å—Ç—ñ, –æ—Å–≤—ñ—Ç–Ω—ñ –ø—Ä–æ–≥—Ä–∞–º–∏, –∫–æ–¥–∏ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—Å—Ç–µ–π",
            "procedural": "–∫—Ä–æ–∫–∏, –ø—Ä–æ—Ü–µ–¥—É—Ä–∞, –ø–æ—Ä—è–¥–æ–∫ –¥—ñ–π, –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏",
            "comparison": "–ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è, —Ä—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ –≤–∞—Ä—ñ–∞–Ω—Ç–∞–º–∏, –ø–µ—Ä–µ–≤–∞–≥–∏",
            "factual": "–∑–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –•–î–£, –∫–æ–Ω—Ç–∞–∫—Ç–∏, –∞–¥—Ä–µ—Å–∞"
        }
        return mapping.get(question_type, "—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –•–î–£")
    
    def _get_search_target(self, question_type: str) -> str:
        """–¶—ñ–ª—å –ø–æ—à—É–∫—É –¥–ª—è —Ç–∏–ø—É –ø–∏—Ç–∞–Ω–Ω—è"""
        mapping = {
            "admission": "–≤—Å—Ç—É–ø –¥–æ –•–î–£ —É 2026 —Ä–æ—Ü—ñ",
            "tuition": "–≤–∞—Ä—Ç—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è –≤ –•–î–£",
            "faculties": "—Ñ–∞–∫—É–ª—å—Ç–µ—Ç–∏ —Ç–∞ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—Å—Ç—ñ –•–î–£",
            "procedural": "–ø—Ä–æ—Ü–µ–¥—É—Ä—É –≤—Å—Ç—É–ø—É –¥–æ –•–î–£",
            "comparison": "–ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –Ω–∞–≤—á–∞–Ω–Ω—è –≤ –•–î–£",
            "factual": "–∑–∞–≥–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –•–î–£"
        }
        return mapping.get(question_type, "—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –•–î–£")
    
    def _should_use_cot(self, question_type: str, query: str) -> bool:
        """–í–∏–∑–Ω–∞—á–∞—î, —á–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω Chain-of-Thought"""
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ CoT –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å
        complex_indicators = [
            "–ø–æ—Ä—ñ–≤–Ω—è–π", "–≤ —á–æ–º—É —Ä—ñ–∑–Ω–∏—Ü—è", "—è–∫ –≤–∏–±—Ä–∞—Ç–∏",
            "—â–æ –∫—Ä–∞—â–µ", "—è–∫–∞ —Ä—ñ–∑–Ω–∏—Ü—è", "—Å–∫—ñ–ª—å–∫–∏ —Ä—ñ–∑–Ω–∏—Ö"
        ]
        
        query_lower = query.lower()
        has_complex_indicator = any(indicator in query_lower for indicator in complex_indicators)
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ CoT –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω—å —Ç–∞ –¥–æ–≤–≥–∏—Ö –ø–∏—Ç–∞–Ω—å
        return question_type == "comparison" or has_complex_indicator or len(query) > 100
    
    def _build_cot_prompt(self, system_prompt: str, query: str) -> str:
        """–ü–æ–±—É–¥–æ–≤–∞ –ø—Ä–æ–º–ø—Ç—É –∑ Chain-of-Thought"""
        cot_instructions = """–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è –∫—Ä–æ–∫ –∑–∞ –∫—Ä–æ–∫–æ–º:

–ö–†–û–ö 1: –†–æ–∑—É–º—ñ–Ω–Ω—è –ø–∏—Ç–∞–Ω–Ω—è
- –ü—Ä–æ —â–æ –ø–∏—Ç–∞—é—Ç—å? (—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—Å—Ç—ñ, –≤–∞—Ä—Ç—ñ—Å—Ç—å, –¥–æ–∫—É–º–µ–Ω—Ç–∏, –∫–æ–Ω—Ç–∞–∫—Ç–∏)
- –Ø–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø–æ—Ç—Ä—ñ–±–Ω–∞?

–ö–†–û–ö 2: –ü–æ—à—É–∫ –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å
- –Ø–∫–∞ —Å–µ–∫—Ü—ñ—è –±–∞–∑–∏ –∑–Ω–∞–Ω—å –º—ñ—Å—Ç–∏—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—å?
- –Ø–∫—ñ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –¥–∞–Ω—ñ –ø–æ—Ç—Ä—ñ–±–Ω—ñ?

–ö–†–û–ö 3: –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
- –Ø–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å?
- –Ø–∫—ñ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –¥–∞–Ω—ñ –≤–∫–ª—é—á–∏—Ç–∏?

–ö–†–û–ö 4: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞
- –ß–∏ –Ω–µ–º–∞—î –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–∏—Ö —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—ñ–≤?
- –ß–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—è?
- –ß–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è?

–í–Ü–î–ü–û–í–Ü–î–¨ (–ø—ñ—Å–ª—è –≤—Å—ñ—Ö –∫—Ä–æ–∫—ñ–≤, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞, —Ç—ñ–ª—å–∫–∏ –ø—Ä–æ –•–î–£):"""
        
        return f"{system_prompt}\n\n{cot_instructions}\n\n–ü–ò–¢–ê–ù–ù–Ø: {query}\n\n"
    
    def _adapt_params(self, params: Dict, query_length: int) -> Dict:
        """–ê–¥–∞–ø—Ç–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –¥–æ–≤–∂–∏–Ω–∏ –ø–∏—Ç–∞–Ω–Ω—è"""
        adapted = params.copy()
        
        # –ê–¥–∞–ø—Ç—É—î–º–æ num_predict –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –¥–æ–≤–∂–∏–Ω–∏ –ø–∏—Ç–∞–Ω–Ω—è
        if query_length < 20:
            adapted["num_predict"] = min(150, adapted["num_predict"])
        elif query_length > 100:
            adapted["num_predict"] = min(800, int(adapted["num_predict"] * 1.2))
        
        return adapted
    
    async def _generate_with_retry(
        self, 
        prompt: str, 
        params: Dict, 
        max_retries: int = 3,
        context: List[Dict] = None
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑ –ø–æ–≤—Ç–æ—Ä–Ω–∏–º–∏ —Å–ø—Ä–æ–±–∞–º–∏ (–æ—Å—Ç–∞–Ω–Ω—è –≤–µ—Ä—Å—ñ—è OLLAMA API)"""
        last_error = None
        
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ —Å–∏—Å—Ç–µ–º–Ω–∏–π –ø—Ä–æ–º–ø—Ç —Ç–∞ –ø–∏—Ç–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        system_prompt = ""
        user_message = prompt
        
        # –Ø–∫—â–æ –ø—Ä–æ–º–ø—Ç –º—ñ—Å—Ç–∏—Ç—å —Ä–æ–∑–¥—ñ–ª—é–≤–∞—á, —Ä–æ–∑–¥—ñ–ª—è—î–º–æ
        if "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" in prompt:
            parts = prompt.split("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
            if len(parts) >= 2:
                system_prompt = parts[0].strip()
                # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –ø–∏—Ç–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
                for part in parts[1:]:
                    if "–ü–ò–¢–ê–ù–ù–Ø –ö–û–†–ò–°–¢–£–í–ê–ß–ê:" in part:
                        user_lines = part.split("\n")
                        for i, line in enumerate(user_lines):
                            if "–ü–ò–¢–ê–ù–ù–Ø –ö–û–†–ò–°–¢–£–í–ê–ß–ê:" in line and i + 1 < len(user_lines):
                                user_message = user_lines[i + 1].strip()
                                break
        else:
            # –Ø–∫—â–æ –Ω–µ–º–∞—î —Ä–æ–∑–¥—ñ–ª—é–≤–∞—á–∞, –≤–µ—Å—å –ø—Ä–æ–º–ø—Ç - —Ü–µ —Å–∏—Å—Ç–µ–º–Ω–∏–π
            system_prompt = prompt
        
        # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è chat API
        messages = []
        
        # –î–æ–¥–∞—î–º–æ —Å–∏—Å—Ç–µ–º–Ω–∏–π –ø—Ä–æ–º–ø—Ç
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        # –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
        if context:
            for ctx in context:
                if isinstance(ctx, dict):
                    if "user_message" in ctx and "bot_response" in ctx:
                        messages.append({
                            "role": "user",
                            "content": ctx["user_message"]
                        })
                        messages.append({
                            "role": "assistant",
                            "content": ctx["bot_response"]
                        })
        
        # –î–æ–¥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        for attempt in range(max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–æ–≤–∏–π chat API (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π –≤ OLLAMA 0.11+)
                    payload = {
                        "model": self.model,
                        "messages": messages,
                        "stream": False,
                        "options": params
                    }
                    
                    # –°–ø—Ä–æ–±—É—î–º–æ —Å–ø–æ—á–∞—Ç–∫—É –Ω–æ–≤–∏–π chat API
                    try:
                        async with session.post(
                            f"{self.api_url}/api/chat",
                            json=payload,
                            timeout=aiohttp.ClientTimeout(total=60)
                        ) as response:
                            if response.status == 200:
                                data = await response.json()
                                # –ù–æ–≤–∏–π —Ñ–æ—Ä–º–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                                if "message" in data:
                                    answer = data["message"].get("content", "").strip()
                                elif "response" in data:
                                    answer = data["response"].strip()
                                else:
                                    answer = str(data).strip()
                                
                                if answer:
                                    return answer
                            else:
                                error_text = await response.text()
                                last_error = f"HTTP {response.status}: {error_text}"
                    except Exception as chat_error:
                        # –Ø–∫—â–æ chat API –Ω–µ –ø—Ä–∞—Ü—é—î, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å—Ç–∞—Ä–∏–π generate API
                        logger.info(f"Chat API –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ generate API: {chat_error}")
                        generate_payload = {
                            "model": self.model,
                            "prompt": prompt,
                            "stream": False,
                            "options": params
                        }
                        
                        async with session.post(
                            f"{self.api_url}/api/generate",
                            json=generate_payload,
                            timeout=aiohttp.ClientTimeout(total=60)
                        ) as response:
                            if response.status == 200:
                                data = await response.json()
                                answer = data.get("response", "").strip()
                                if answer:
                                    return answer
                            else:
                                error_text = await response.text()
                                last_error = f"HTTP {response.status}: {error_text}"
                    
                    if attempt < max_retries - 1:
                        await asyncio.sleep(1)  # –ó–∞—Ç—Ä–∏–º–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ—é —Å–ø—Ä–æ–±–æ—é
                            
            except asyncio.TimeoutError:
                last_error = "Timeout"
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)
            except Exception as e:
                last_error = str(e)
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)
                else:
                    logger.error(f"Error generating response: {e}")
        
        from knowledge_base import get_admissions_committee_phones
        return f"–í–∏–±–∞—á, –Ω–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å. –°–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏ –ø–∏—Ç–∞–Ω–Ω—è –∞–±–æ –∑–≤–µ—Ä–Ω–∏—Å—è –¥–æ –ø—Ä–∏–π–º–∞–ª—å–Ω–æ—ó –∫–æ–º—ñ—Å—ñ—ó –•–î–£:\n\n{get_admissions_committee_phones()}"
    
    async def generate_response_stream(
        self,
        prompt: str,
        context: List[Dict] = None,
        use_cache: bool = True
    ) -> AsyncGenerator[str, None]:
        """
        Streaming –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ - –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –±–∞—á–∏—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ø–æ —á–∞—Å—Ç–∏–Ω–∞—Ö
        –ï—Ñ–µ–∫—Ç: -40-60% —á–∞—Å—É –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        """
        start_time = time.time()
        
        if not prompt:
            yield "–í–∏–±–∞—á, –Ω–µ –∑—Ä–æ–∑—É–º—ñ–≤ –ø–∏—Ç–∞–Ω–Ω—è. –°–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏."
            return
        
        # 1. –ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î–º–æ –ø–∏—Ç–∞–Ω–Ω—è
        question_type = self.question_classifier.classify(prompt)
        
        # 2. –û—Ç—Ä–∏–º—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        full_context = self.knowledge_service.get_context_for_prompt(prompt)
        optimized_context = self.context_optimizer.optimize_context(
            prompt,
            full_context["structured_json"]
        )
        
        # 3. –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à (—Å–ø–æ—á–∞—Ç–∫—É —Ç–æ—á–Ω–∏–π, –ø–æ—Ç—ñ–º —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π)
        if use_cache:
            # –¢–æ—á–Ω–∏–π –ø–æ—à—É–∫
            cached_response = self.cache.get(prompt, optimized_context)
            if cached_response:
                response_time = time.time() - start_time
                self.metrics.record_request(
                    prompt, cached_response, response_time,
                    from_cache=True, question_type=question_type, validation_passed=True
                )
                logger.info(f"Exact cache hit for question type: {question_type}")
                yield cached_response
                return
            
            # –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫
            semantic_result = self.semantic_cache.get(prompt, optimized_context)
            if semantic_result:
                cached_response, similarity = semantic_result
                response_time = time.time() - start_time
                self.metrics.record_request(
                    prompt, cached_response, response_time,
                    from_cache=True, question_type=question_type, validation_passed=True
                )
                logger.info(f"Semantic cache hit (similarity: {similarity:.2f}) for question type: {question_type}")
                yield cached_response
                return
        
        # 4. –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø–∏—Ç–∞–Ω–Ω—è
        analyzed_query = self._analyze_and_enhance_query(prompt, question_type)
        
        # 5. –§–æ—Ä–º—É—î–º–æ –ø—Ä–æ–º–ø—Ç
        system_prompt = self.prompt_builder.build_system_prompt(
            question_type,
            optimized_context,
            user_query=prompt
        )
        
        # 6. –î–æ–¥–∞—î–º–æ Chain-of-Thought —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
        if self._should_use_cot(question_type, prompt):
            full_prompt = self._build_cot_prompt(system_prompt, analyzed_query)
        else:
            full_prompt = f"""{system_prompt}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ü–ò–¢–ê–ù–ù–Ø –ö–û–†–ò–°–¢–£–í–ê–ß–ê:
{prompt}

–ü–†–û–ê–ù–ê–õ–Ü–ó–û–í–ê–ù–ï –ü–ò–¢–ê–ù–ù–Ø:
{analyzed_query}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
1. –£–≤–∞–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π –ø–∏—Ç–∞–Ω–Ω—è
2. –ó–Ω–∞–π–¥–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å –≤–∏—â–µ
3. –°—Ñ–æ—Ä–º—É–π —Ç–æ—á–Ω—É, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å
4. –ü–µ—Ä–µ–≤—ñ—Ä –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞ —Å–ø–∏—Å–∫–æ–º —Å–∞–º–æ–ø–µ—Ä–µ–≤—ñ—Ä–∫–∏

–í–Ü–î–ü–û–í–Ü–î–¨ (—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞, –∑ –¥–∞–Ω–∏–º–∏ –∑ –±–∞–∑–∏ –∑–Ω–∞–Ω—å):"""
        
        # 7. –û—Ç—Ä–∏–º—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
        params = self.generation_params.get(
            question_type,
            self.generation_params["default"]
        )
        params = self._adapt_params(params, len(prompt))
        
        # 8. Streaming –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è
        full_response = ""
        try:
            async for chunk in self._generate_stream(full_prompt, params, context):
                full_response += chunk
                yield chunk
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ streaming –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {e}")
            yield f"–í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –°–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏ –ø–∏—Ç–∞–Ω–Ω—è."
            return
        
        # 9. –í–∞–ª—ñ–¥—É—î–º–æ –ø–æ–≤–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å
        validation_result = self.validator.validate(full_response, prompt)
        
        # 10. –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –∫–µ—à (–æ–±–∏–¥–≤–∞ —Ç–∏–ø–∏)
        if validation_result.is_valid and use_cache and full_response:
            self.cache.set(prompt, optimized_context, full_response)
            self.semantic_cache.set(prompt, optimized_context, full_response)
        
        # 11. –ó–∞–ø–∏—Å—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
        response_time = time.time() - start_time
        self.metrics.record_request(
            prompt, full_response, response_time,
            from_cache=False, question_type=question_type,
            validation_passed=validation_result.is_valid
        )
    
    async def _generate_stream(
        self,
        prompt: str,
        params: Dict,
        context: List[Dict] = None
    ) -> AsyncGenerator[str, None]:
        """–í–Ω—É—Ç—Ä—ñ—à–Ω—ñ–π –º–µ—Ç–æ–¥ –¥–ª—è streaming –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó"""
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ —Å–∏—Å—Ç–µ–º–Ω–∏–π –ø—Ä–æ–º–ø—Ç —Ç–∞ –ø–∏—Ç–∞–Ω–Ω—è
        system_prompt = ""
        user_message = prompt
        
        if "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê" in prompt:
            parts = prompt.split("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
            if len(parts) >= 2:
                system_prompt = parts[0].strip()
                for part in parts[1:]:
                    if "–ü–ò–¢–ê–ù–ù–Ø –ö–û–†–ò–°–¢–£–í–ê–ß–ê:" in part:
                        user_lines = part.split("\n")
                        for i, line in enumerate(user_lines):
                            if "–ü–ò–¢–ê–ù–ù–Ø –ö–û–†–ò–°–¢–£–í–ê–ß–ê:" in line and i + 1 < len(user_lines):
                                user_message = user_lines[i + 1].strip()
                                break
        else:
            system_prompt = prompt
        
        # –§–æ—Ä–º—É—î–º–æ messages
        messages = []
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        if context:
            for ctx in context:
                if isinstance(ctx, dict):
                    if "user_message" in ctx and "bot_response" in ctx:
                        messages.append({
                            "role": "user",
                            "content": ctx["user_message"]
                        })
                        messages.append({
                            "role": "assistant",
                            "content": ctx["bot_response"]
                        })
        
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        # Streaming –∑–∞–ø–∏—Ç
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": self.model,
                    "messages": messages,
                    "stream": True,  # –£–≤—ñ–º–∫–Ω—É—Ç–∏ streaming
                    "options": params
                }
                
                async with session.post(
                    f"{self.api_url}/api/chat",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=120)
                ) as response:
                    if response.status == 200:
                        buffer = ""
                        async for chunk_bytes in response.content.iter_chunked(1024):
                            if chunk_bytes:
                                try:
                                    buffer += chunk_bytes.decode('utf-8', errors='ignore')
                                    # –û–±—Ä–æ–±–ª—è—î–º–æ –ø–æ–≤–Ω—ñ JSON —Ä—è–¥–∫–∏
                                    while '\n' in buffer:
                                        line, buffer = buffer.split('\n', 1)
                                        line = line.strip()
                                        if line:
                                            try:
                                                data = json.loads(line)
                                                # OLLAMA streaming —Ñ–æ—Ä–º–∞—Ç
                                                if "message" in data:
                                                    message = data["message"]
                                                    if isinstance(message, dict) and "content" in message:
                                                        chunk = message["content"]
                                                        if chunk:
                                                            yield chunk
                                                    elif isinstance(message, str):
                                                        yield message
                                                elif "response" in data:
                                                    chunk = data["response"]
                                                    if chunk:
                                                        yield chunk
                                                elif "delta" in data and "content" in data["delta"]:
                                                    # –î–µ–ª—å—Ç–∞ —Ñ–æ—Ä–º–∞—Ç
                                                    chunk = data["delta"]["content"]
                                                    if chunk:
                                                        yield chunk
                                            except json.JSONDecodeError:
                                                continue
                                except Exception as e:
                                    logger.debug(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ streaming chunk: {e}")
                                    continue
                        # –û–±—Ä–æ–±–ª—è—î–º–æ –∑–∞–ª–∏—à–æ–∫ –±—É—Ñ–µ—Ä–∞
                        if buffer.strip():
                            try:
                                data = json.loads(buffer.strip())
                                if "message" in data and "content" in data["message"]:
                                    chunk = data["message"]["content"]
                                    if chunk:
                                        yield chunk
                            except json.JSONDecodeError:
                                pass
                    else:
                        error_text = await response.text()
                        logger.error(f"Streaming –ø–æ–º–∏–ª–∫–∞ HTTP {response.status}: {error_text}")
                        yield f"–í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ."
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ streaming –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {e}")
            yield f"–í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ."
    
    async def check_health(self) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ OLLAMA (–æ—Å—Ç–∞–Ω–Ω—è –≤–µ—Ä—Å—ñ—è API)"""
        try:
            async with aiohttp.ClientSession() as session:
                # –°–ø—Ä–æ–±—É—î–º–æ –Ω–æ–≤–∏–π API —Å–ø–æ—á–∞—Ç–∫—É
                try:
                    async with session.get(
                        f"{self.api_url}/api/tags",
                        timeout=aiohttp.ClientTimeout(total=5)
                    ) as response:
                        if response.status == 200:
                            return True
                except:
                    pass
                
                # –Ø–∫—â–æ –Ω–µ –ø—Ä–∞—Ü—é—î, —Å–ø—Ä–æ–±—É—î–º–æ —Å—Ç–∞—Ä–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
                try:
                    async with session.get(
                        f"{self.api_url}/api/version",
                        timeout=aiohttp.ClientTimeout(total=5)
                    ) as response:
                        return response.status == 200
                except:
                    return False
        except:
            return False
    
    def get_statistics(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–æ–±–æ—Ç–∏"""
        return self.metrics.get_statistics()
    
    def get_cache_stats(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–µ—à—É"""
        exact_stats = self.cache.get_stats()
        semantic_stats = self.semantic_cache.get_stats()
        return {
            "exact_cache": exact_stats,
            "semantic_cache": semantic_stats,
            "total_entries": exact_stats["size"] + semantic_stats["size"]
        }
    
    async def generate_response_parallel(
        self,
        prompt: str,
        context: List[Dict] = None,
        num_candidates: int = 3,
        use_cache: bool = True
    ) -> str:
        """
        –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫—ñ–ª—å–∫–æ—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —Ç–∞ –≤–∏–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ
        –ï—Ñ–µ–∫—Ç: +20% —à–≤–∏–¥–∫–æ—Å—Ç—ñ —Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å
        """
        start_time = time.time()
        
        if not prompt:
            return "–í–∏–±–∞—á, –Ω–µ –∑—Ä–æ–∑—É–º—ñ–≤ –ø–∏—Ç–∞–Ω–Ω—è. –°–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏."
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à –ø–µ—Ä–µ–¥ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—é –≥–µ–Ω–µ—Ä–∞—Ü—ñ—î—é
        if use_cache:
            question_type = self.question_classifier.classify(prompt)
            full_context = self.knowledge_service.get_context_for_prompt(prompt)
            optimized_context = self.context_optimizer.optimize_context(
                prompt,
                full_context["structured_json"]
            )
            
            cached_response = self.cache.get(prompt, optimized_context)
            if cached_response:
                return cached_response
            
            semantic_result = self.semantic_cache.get(prompt, optimized_context)
            if semantic_result:
                return semantic_result[0]
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ –∫—ñ–ª—å–∫–∞ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ
        question_type = self.question_classifier.classify(prompt)
        full_context = self.knowledge_service.get_context_for_prompt(prompt)
        optimized_context = self.context_optimizer.optimize_context(
            prompt,
            full_context["structured_json"]
        )
        
        analyzed_query = self._analyze_and_enhance_query(prompt, question_type)
        system_prompt = self.prompt_builder.build_system_prompt(
            question_type,
            optimized_context,
            user_query=prompt
        )
        
        if self._should_use_cot(question_type, prompt):
            full_prompt = self._build_cot_prompt(system_prompt, analyzed_query)
        else:
            full_prompt = f"""{system_prompt}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ü–ò–¢–ê–ù–ù–Ø –ö–û–†–ò–°–¢–£–í–ê–ß–ê:
{prompt}

–ü–†–û–ê–ù–ê–õ–Ü–ó–û–í–ê–ù–ï –ü–ò–¢–ê–ù–ù–Ø:
{analyzed_query}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
1. –£–≤–∞–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π –ø–∏—Ç–∞–Ω–Ω—è
2. –ó–Ω–∞–π–¥–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å –≤–∏—â–µ
3. –°—Ñ–æ—Ä–º—É–π —Ç–æ—á–Ω—É, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å
4. –ü–µ—Ä–µ–≤—ñ—Ä –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞ —Å–ø–∏—Å–∫–æ–º —Å–∞–º–æ–ø–µ—Ä–µ–≤—ñ—Ä–∫–∏

–í–Ü–î–ü–û–í–Ü–î–¨ (—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞, –∑ –¥–∞–Ω–∏–º–∏ –∑ –±–∞–∑–∏ –∑–Ω–∞–Ω—å):"""
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –±–∞–∑–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
        base_params = self.generation_params.get(
            question_type,
            self.generation_params["default"]
        )
        base_params = self._adapt_params(base_params, len(prompt))
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –≤–∞—Ä—ñ–∞—Ü—ñ—ó –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤
        param_variations = self._create_param_variations(base_params, num_candidates)
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—Å—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ
        tasks = [
            self._generate_with_retry(
                full_prompt,
                params,
                max_retries=2,
                context=context if context else []
            )
            for params in param_variations
        ]
        
        try:
            candidates = await asyncio.gather(*tasks, return_exceptions=True)
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {e}")
            # Fallback –¥–æ –∑–≤–∏—á–∞–π–Ω–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
            return await self._generate_with_retry(
                full_prompt,
                base_params,
                max_retries=3,
                context=context if context else []
            )
        
        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ø–æ–º–∏–ª–∫–∏
        valid_candidates = [
            c for c in candidates
            if isinstance(c, str) and len(c.strip()) > 20
        ]
        
        if not valid_candidates:
            # –Ø–∫—â–æ –≤—Å—ñ –Ω–µ–≤–∞–ª—ñ–¥–Ω—ñ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback
            return await self._generate_with_retry(
                full_prompt,
                base_params,
                max_retries=3,
                context=context if context else []
            )
        
        # –í–∏–±–∏—Ä–∞—î–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
        best_response = self._select_best_response(valid_candidates, prompt, question_type)
        
        # –í–∞–ª—ñ–¥—É—î–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
        validation_result = self.validator.validate(best_response, prompt)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –∫–µ—à
        if validation_result.is_valid and use_cache:
            self.cache.set(prompt, optimized_context, best_response)
            self.semantic_cache.set(prompt, optimized_context, best_response)
        
        # –ó–∞–ø–∏—Å—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
        response_time = time.time() - start_time
        self.metrics.record_request(
            prompt, best_response, response_time,
            from_cache=False, question_type=question_type,
            validation_passed=validation_result.is_valid
        )
        
        return best_response
    
    def _create_param_variations(self, base_params: Dict, num_variations: int) -> List[Dict]:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–∞—Ä—ñ–∞—Ü—ñ–π –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó"""
        variations = []
        
        for i in range(num_variations):
            params = base_params.copy()
            
            # –í–∞—Ä—ñ–∞—Ü—ñ—ó temperature
            if i == 0:
                params["temperature"] = max(0.0, base_params.get("temperature", 0.05) - 0.02)
            elif i == 1:
                params["temperature"] = base_params.get("temperature", 0.05)
            else:
                params["temperature"] = min(0.3, base_params.get("temperature", 0.05) + 0.02)
            
            # –í–∞—Ä—ñ–∞—Ü—ñ—ó top_p
            if i % 2 == 0:
                params["top_p"] = max(0.2, base_params.get("top_p", 0.4) - 0.05)
            else:
                params["top_p"] = min(0.8, base_params.get("top_p", 0.4) + 0.05)
            
            # –í–∞—Ä—ñ–∞—Ü—ñ—ó num_predict
            if i == 0:
                params["num_predict"] = int(base_params.get("num_predict", 400) * 0.9)
            elif i == 1:
                params["num_predict"] = base_params.get("num_predict", 400)
            else:
                params["num_predict"] = int(base_params.get("num_predict", 400) * 1.1)
            
            variations.append(params)
        
        return variations
    
    def _select_best_response(self, candidates: List[str], prompt: str, question_type: str) -> str:
        """–í–∏–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –≤–∞—Ä—ñ–∞–Ω—Ç—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"""
        if len(candidates) == 1:
            return candidates[0]
        
        scores = []
        
        for candidate in candidates:
            score = 0.0
            
            # 1. –î–æ–≤–∂–∏–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞ 100-500 —Å–∏–º–≤–æ–ª—ñ–≤)
            length = len(candidate)
            if 100 <= length <= 500:
                score += 0.3
            elif 50 <= length < 100 or 500 < length <= 1000:
                score += 0.2
            else:
                score += 0.1
            
            # 2. –ù–∞—è–≤–Ω—ñ—Å—Ç—å –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ –¥–ª—è —Ç–∏–ø—É –ø–∏—Ç–∞–Ω–Ω—è
            candidate_lower = candidate.lower()
            prompt_lower = prompt.lower()
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –º—ñ—Å—Ç–∏—Ç—å –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑ –ø–∏—Ç–∞–Ω–Ω—è
            prompt_keywords = set(re.findall(r'\b\w{4,}\b', prompt_lower))
            candidate_keywords = set(re.findall(r'\b\w{4,}\b', candidate_lower))
            common_keywords = prompt_keywords & candidate_keywords
            
            if prompt_keywords:
                keyword_score = len(common_keywords) / len(prompt_keywords)
                score += keyword_score * 0.3
            
            # 3. –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ—Å—Ç—å (–Ω–∞—è–≤–Ω—ñ—Å—Ç—å —Å–ø–∏—Å–∫—ñ–≤, —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è)
            has_structure = bool(
                re.search(r'[‚Ä¢\-\d+\.]', candidate) or
                '\n' in candidate or
                ':' in candidate
            )
            if has_structure:
                score += 0.2
            
            # 4. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–∏—Ö —Å–ª—ñ–≤
            forbidden_words = ['—Ö–Ω—É', '–∫–Ω—É', '–ª—å–≤—ñ–≤—Å—å–∫–∏–π', '–æ–¥–µ—Å—å–∫–∏–π', '—Ö–∞—Ä–∫—ñ–≤—Å—å–∫–∏–π']
            has_forbidden = any(word in candidate_lower for word in forbidden_words)
            if not has_forbidden:
                score += 0.2
            else:
                score -= 1.0  # –í–µ–ª–∏–∫–∏–π —à—Ç—Ä–∞—Ñ –∑–∞ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω—ñ —Å–ª–æ–≤–∞
            
            scores.append(score)
        
        # –í–∏–±–∏—Ä–∞—î–º–æ –≤–∞—Ä—ñ–∞–Ω—Ç –∑ –Ω–∞–π–≤–∏—â–∏–º –±–∞–ª–æ–º
        best_index = scores.index(max(scores))
        return candidates[best_index]
    
    def _get_admission_fallback(self, query: str) -> str:
        """Fallback –≤—ñ–¥–ø–æ–≤—ñ–¥—å –¥–ª—è –ø–∏—Ç–∞–Ω—å –ø—Ä–æ –≤—Å—Ç—É–ø"""
        try:
            from knowledge_base import get_admission_2026_info, get_admissions_committee_phones
            import json
            
            info = get_admission_2026_info()
            if not info:
                return self._get_default_admission_response()
            
            # –§–æ—Ä–º–∞—Ç—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
            parts = []
            parts.append("üìò <b>–ü—Ä–∞–≤–∏–ª–∞ –≤—Å—Ç—É–ø—É –¥–æ –•–î–£ —É 2026 —Ä–æ—Ü—ñ</b>")
            
            if info.get("description"):
                parts.append(info["description"])
            
            nmt = info.get("nmt", {})
            if nmt:
                mandatory = nmt.get("mandatory_subjects", [])
                optional = nmt.get("optional_subjects", [])
                valid_years = nmt.get("valid_years", [])
                
                if mandatory:
                    parts.append("üß™ <b>–ù–ú–¢ - –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π –±–ª–æ–∫:</b>")
                    parts.extend([f"‚Ä¢ {s}" for s in mandatory])
                
                if optional:
                    parts.append("üìö <b>–ü—Ä–µ–¥–º–µ—Ç –Ω–∞ –≤–∏–±—ñ—Ä:</b>")
                    parts.extend([f"‚Ä¢ {s}" for s in optional[:3]])  # –ü–µ—Ä—à—ñ 3
                
                if valid_years:
                    years = ", ".join(str(y) for y in valid_years)
                    parts.append(f"üìÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–ú–¢ –≤—Ä–∞—Ö–æ–≤—É—é—Ç—å—Å—è –∑–∞ {years} —Ä–æ–∫–∏")
            
            trajectories = info.get("trajectories", {})
            if trajectories:
                bachelor = trajectories.get("bachelor", {})
                master = trajectories.get("master", {})
                
                parts.append("üéì <b>–¢—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –≤—Å—Ç—É–ø—É:</b>")
                
                if bachelor:
                    duration = bachelor.get("duration", {})
                    if duration:
                        if duration.get("bachelor"):
                            parts.append(f"‚Ä¢ –ë–∞–∫–∞–ª–∞–≤—Ä: {duration['bachelor']}")
                        if duration.get("medical_master"):
                            parts.append(f"‚Ä¢ –ú–µ–¥–∏—á–Ω–∏–π –º–∞–≥—ñ—Å—Ç—Ä: {duration['medical_master']}")
                        if duration.get("pharmacy_master"):
                            parts.append(f"‚Ä¢ –§–∞—Ä–º–∞—Ü–µ–≤—Ç–∏—á–Ω–∏–π –º–∞–≥—ñ—Å—Ç—Ä: {duration['pharmacy_master']}")
                
                if master:
                    duration = master.get("duration", {})
                    if duration:
                        if duration.get("standard"):
                            parts.append(f"‚Ä¢ –ú–∞–≥—ñ—Å—Ç—Ä: {duration['standard']}")
                        if duration.get("extended"):
                            parts.append(f"‚Ä¢ –ú–∞–≥—ñ—Å—Ç—Ä (–æ–∫—Ä–µ–º—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—Å—Ç—ñ): {duration['extended']}")
            
            campaign = info.get("campaign", {})
            if campaign:
                period = campaign.get("period")
                if period:
                    parts.append(f"\n‚è∞ <b>–ü–µ—Ä—ñ–æ–¥ –∫–∞–º–ø–∞–Ω—ñ—ó:</b> {period}")
                
                electronic_cabinets = campaign.get("electronic_cabinets", {})
                if electronic_cabinets:
                    platform = electronic_cabinets.get("platform")
                    if platform:
                        parts.append(f"üíª <b>–ï–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∏–π –∫–∞–±—ñ–Ω–µ—Ç:</b> {platform}")
                    
                    description = electronic_cabinets.get("description")
                    if description:
                        parts.append(f"üìù {description}")
            
            parts.append(f"\n{get_admissions_committee_phones()}")
            
            result = "\n".join(parts)
            # –í–∏–¥–∞–ª—è—î–º–æ HTML —Ç–µ–≥–∏ –¥–ª—è fallback (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
            # –ê–ª–µ –∑–∞–ª–∏—à–∞—î–º–æ –¥–ª—è Telegram
            return result
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è fallback –¥–ª—è –≤—Å—Ç—É–ø—É: {e}")
            return self._get_default_admission_response()
    
    def _get_default_admission_response(self) -> str:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ø—Ä–æ –≤—Å—Ç—É–ø"""
        return """üìò <b>–ü—Ä–∞–≤–∏–ª–∞ –≤—Å—Ç—É–ø—É –¥–æ –•–î–£ —É 2026 —Ä–æ—Ü—ñ</b>

üß™ <b>–ù–ú–¢ (–ù–∞—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π –º—É–ª—å—Ç–∏–ø—Ä–µ–¥–º–µ—Ç–Ω–∏–π —Ç–µ—Å—Ç):</b>
‚Ä¢ –û–±–æ–≤'—è–∑–∫–æ–≤–∏–π –±–ª–æ–∫: –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞, –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –Ü—Å—Ç–æ—Ä—ñ—è –£–∫—Ä–∞—ó–Ω–∏
‚Ä¢ –ü—Ä–µ–¥–º–µ—Ç –Ω–∞ –≤–∏–±—ñ—Ä: –Ü–Ω–æ–∑–µ–º–Ω–∞ –º–æ–≤–∞, –ë—ñ–æ–ª–æ–≥—ñ—è, –ì–µ–æ–≥—Ä–∞—Ñ—ñ—è, –§—ñ–∑–∏–∫–∞, –•—ñ–º—ñ—è –∞–±–æ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∞
‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–ú–¢ 2023-2026 —Ä–æ–∫—ñ–≤ –≤—Ä–∞—Ö–æ–≤—É—é—Ç—å—Å—è

üéì <b>–¢—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –≤—Å—Ç—É–ø—É:</b>
‚Ä¢ –ë–∞–∫–∞–ª–∞–≤—Ä: 3 —Ä–æ–∫–∏ 10 –º—ñ—Å—è—Ü—ñ–≤
‚Ä¢ –ú–∞–≥—ñ—Å—Ç—Ä: 1 —Ä—ñ–∫ 4 –º—ñ—Å—è—Ü—ñ (–±—ñ–ª—å—à—ñ—Å—Ç—å —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—Å—Ç–µ–π)

‚è∞ <b>–í—Å—Ç—É–ø–Ω–∞ –∫–∞–º–ø–∞–Ω—ñ—è:</b>
‚Ä¢ –†–æ–∑–ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –≤–ª—ñ—Ç–∫—É —Ç–∞ —Ç—Ä–∏–≤–∞—î –¥–æ –≤–µ—Ä–µ—Å–Ω—è
‚Ä¢ –ú–æ–∂–ª–∏–≤—ñ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Ö–≤–∏–ª—ñ –∑–∞—Ä–∞—Ö—É–≤–∞–Ω–Ω—è

üíª <b>–ï–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∏–π –∫–∞–±—ñ–Ω–µ—Ç:</b> KSU24
‚Ä¢ –ü–æ–¥–∞—á–∞ –∑–∞—è–≤ —á–µ—Ä–µ–∑ –µ–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∏–π –∫–∞–±—ñ–Ω–µ—Ç
‚Ä¢ –î–∏—Å—Ç–∞–Ω—Ü—ñ–π–Ω–µ —É–∫–ª–∞–¥–∞–Ω–Ω—è —É–≥–æ–¥–∏ –Ω–∞ –Ω–∞–≤—á–∞–Ω–Ω—è

üìû <b>–ü—Ä–∏–π–º–∞–ª—å–Ω–∞ –∫–æ–º—ñ—Å—ñ—è –•–î–£:</b>
üì± +380 552 494375
üì± +38 095 59 29 149
üì± +38 096 61 30 516
üìç –º. –•–µ—Ä—Å–æ–Ω, –≤—É–ª. –£–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å—å–∫–∞, 27"""

